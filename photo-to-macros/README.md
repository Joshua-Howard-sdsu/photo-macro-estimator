# ðŸ“¸ðŸ½ï¸ Photoâ€‘toâ€‘Meal Macro Estimator

*A lightweight, APIâ€‘first service that turns a food photo into an instant macronutrient log for **NomLog***

---

## 1. What is this?

A full-stack application that:

1. Accepts an image upload from the user.
2. (Right now) always classifies it as "pizza" with fixed macros (mocked for testing).
3. Returns fake calories, protein, carbs & fats.
4. Includes a GPTâ€‘style summary blurb (also mocked).

> **What's working now:** File upload to FastAPI is functional via Swagger UI (`/docs`) and through the React frontend.
> You can test the endpoint with any image to simulate a full recognition + nutrition result.

---

## 2. Project structure

```text
â”œâ”€ photo-to-macros/        # Main project directory
â”‚  â”œâ”€ api/                 # FastAPI service (mock working now)
â”‚  â”‚  â”œâ”€ main.py           # /analyze route
â”‚  â”‚  â”œâ”€ food_lookup.py    # mocked macros (returns pizza)
â”‚  â”‚  â””â”€ prompts.py        # mocked GPT blurb
â”‚  â”œâ”€ data/
â”‚  â”‚  â””â”€ usda_food.csv     # (not used yet)
â”‚  â”œâ”€ frontend/            # React frontend (NomLog UI)
â”‚  â”‚  â”œâ”€ src/              # React source code
â”‚  â”‚  â”‚  â”œâ”€ components/    # UI components
â”‚  â”‚  â”‚  â”œâ”€ pages/         # Application pages
â”‚  â”‚  â”‚  â””â”€ utils/         # Utilities
â”‚  â”‚  â”œâ”€ public/           # Public assets
â”‚  â”‚  â”œâ”€ index.html        # HTML template
â”‚  â”‚  â””â”€ package.json      # Frontend dependencies
â”‚  â”œâ”€ .env.sample          # API keys (Google, OpenAI)
â”‚  â”œâ”€ .gitignore
â”‚  â””â”€ requirements.txt     # Python dependencies
â”œâ”€ .venv/                  # Python virtual environment
â””â”€ README.md               # you are here
```

---

## 3. Quickâ€‘start (local)

```bash
# 1. Clone & enter
$ git clone https://github.com/Joshua-Howard-sdsu/photo-macro-estimator.git
$ cd photo-macro-estimator

# 2. Set up virtual environment
$ python -m venv .venv
$ .venv\Scripts\activate

# 3. Install backend requirements
$ pip install -r photo-to-macros/requirements.txt

# 4. Run FastAPI server
$ uvicorn photo-to-macros.api.main:app --reload

# 5. In a new terminal, install and run the frontend
$ cd photo-to-macros/frontend
$ npm install
$ npm run dev
```

Visit:
- Backend API: [http://localhost:8000/docs](http://localhost:8000/docs)
- Frontend: [http://localhost:5173](http://localhost:5173)

---

## 4. Key endpoints

| Method | Route                | Purpose                                                                 |
| ------ | -------------------- | ----------------------------------------------------------------------- |
| `POST` | `/analyze`           | Upload image â†’ get fixed label ("pizza") and fake macros + summary     |

---

## 5. What's coming next?

- ðŸ”„ Replace mock label with real **Google Cloud Vision API** response
- ðŸ“Š Replace fake macros with **USDA CSV** lookup
- ðŸ¤– Replace fake GPT summary with **real GPT-4 API** call
- ðŸ“± Mobile-responsive improvements to the frontend

---

## 6. AI techniques used ðŸš€

| Course topic                 | Where it appears                                     |
| ---------------------------- | ---------------------------------------------------- |
| **Supervised Learning**      | (planned) via Google Vision's food classification     |
| **Knowledge Representation** | USDA food â†’ macro lookup                             |
| **LLM prompting**            | GPT summary generation (mocked for now)              |

---

## 7. License

MIT Â© 2025 Josh Howard

